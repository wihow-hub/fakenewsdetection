{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ip7Yas3W-kax",
    "outputId": "2e3960ac-415d-4be0-a07e-e37baaaafb35"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1v3cCTG0-lD8",
    "outputId": "acb32183-3b62-43e3-92cf-e602ebeff353"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mon Nov 28 09:42:45 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   55C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "De5cri1u_Yrq",
    "outputId": "29672694-b5c7-448f-876a-fd63fa5cab4e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/drive/MyDrive/fakenews\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/fakenews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xoE_wL-k_Z07",
    "outputId": "9d39b33c-d6c4-42e9-ed73-50aec996aa0c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting transformers==4.4.2\n",
      "  Downloading transformers-4.4.2-py3-none-any.whl (2.0 MB)\n",
      "\u001B[K     |████████████████████████████████| 2.0 MB 7.0 MB/s \n",
      "\u001B[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.2) (3.8.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.2) (4.64.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.2) (2022.6.2)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001B[K     |████████████████████████████████| 880 kB 61.2 MB/s \n",
      "\u001B[?25hCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001B[K     |████████████████████████████████| 3.3 MB 54.3 MB/s \n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.2) (1.21.6)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.2) (21.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.2) (2.23.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.2) (4.13.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.4.2) (3.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.4.2) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.4.2) (3.0.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.4.2) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.4.2) (2022.9.24)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.4.2) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.4.2) (3.0.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.4.2) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.4.2) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.4.2) (1.2.0)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=ea0d768718d1236c744a31c442e2a6bddb1ff0e772eebc44df95aa8950134b29\n",
      "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_jUH6Xau_mMM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json,time\n",
    "import os\n",
    "import pdb\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score,classification_report,roc_auc_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset,DataLoader,RandomSampler,SequentialSampler\n",
    "\n",
    "from transformers import BertModel,BertConfig,BertTokenizer,AdamW,get_cosine_schedule_with_warmup\n",
    "\n",
    "bert_path = \"bert_model\"\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-ctZBXiH_pdS"
   },
   "outputs": [],
   "source": [
    "data_split = 'train'\n",
    "path = os.path.join('./data/',data_split)\n",
    "file_name = os.path.join(path,'news.csv')\n",
    "train_frame = pd.read_csv(file_name)\n",
    "train_frame['Report Content'] = train_frame['Report Content'].apply(lambda x:x.split('##'))\n",
    "data_split = 'test'\n",
    "path = os.path.join('./data/',data_split)\n",
    "file_name = os.path.join(path,'news.csv')\n",
    "test_frame = pd.read_csv(file_name)\n",
    "test_frame['Report Content'] = test_frame['Report Content'].apply(lambda x:x.split('##'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QBBXADzQ_rO6",
    "outputId": "59b88c5e-2a84-4411-ca8b-05d3253958b0"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(10587, 70) (10587, 70) (10587, 70) (10587,)\n",
      "(10141, 70) (10141, 70) (10141, 70) (10141,)\n"
     ]
    }
   ],
   "source": [
    "input_ids,input_masks,input_types = [],[],[]\n",
    "input_ids_test,input_masks_test,input_types_test = [],[],[]\n",
    "labels = []\n",
    "labels_test = []\n",
    "maxlen = 70\n",
    "\n",
    "for i,line in train_frame.iterrows():\n",
    "    title,y = str(line['Ofiicial Account Name'])+':'+line['Title']+str(line['Report Content']),line['label']\n",
    "\n",
    "    encode_dict = tokenizer.encode_plus(text=title,max_length=maxlen,padding='max_length',truncation=True)\n",
    "\n",
    "    input_ids.append(encode_dict['input_ids'])\n",
    "    input_types.append(encode_dict['token_type_ids'])\n",
    "    input_masks.append(encode_dict['attention_mask'])\n",
    "\n",
    "    labels.append(int(y))\n",
    "\n",
    "for i,line in test_frame.iterrows():\n",
    "    title,y = str(line['Ofiicial Account Name'])+':'+line['Title']+str(line['Report Content']),line['label']\n",
    "\n",
    "    encode_dict = tokenizer.encode_plus(text=title,max_length=maxlen,padding='max_length',truncation=True)\n",
    "\n",
    "    input_ids_test.append(encode_dict['input_ids'])\n",
    "    input_types_test.append(encode_dict['token_type_ids'])\n",
    "    input_masks_test.append(encode_dict['attention_mask'])\n",
    "\n",
    "    labels_test.append(int(y))\n",
    "\n",
    "\n",
    "\n",
    "input_ids, input_types, input_masks = np.array(input_ids), np.array(input_types), np.array(input_masks)\n",
    "labels = np.array(labels)\n",
    "print(input_ids.shape, input_types.shape, input_masks.shape, labels.shape)\n",
    "\n",
    "input_ids_test, input_types_test, input_masks_test = np.array(input_ids_test), np.array(input_types_test), np.array(input_masks_test)\n",
    "labels_test = np.array(labels_test)\n",
    "print(input_ids_test.shape, input_types_test.shape, input_masks_test.shape,labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wb6NcPlC_s4M",
    "outputId": "84c042a0-6082-438f-f3e5-36c49a6ecbb6"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(10587,) [7005 5389  563 1162 4571 4907  851 3336 7705 8574]\n",
      "(9000, 70) (9000,) (1587, 70) (1587,) (10141, 70) (10141,)\n"
     ]
    }
   ],
   "source": [
    "# 随机打乱索引\n",
    "idxes = np.arange(input_ids.shape[0])\n",
    "np.random.seed(2022)   # 固定种子\n",
    "np.random.shuffle(idxes)\n",
    "print(idxes.shape, idxes[:10])\n",
    "\n",
    "input_ids_train, input_ids_valid, input_ids_test = input_ids[idxes[:9000]], input_ids[idxes[9000:10587]], input_ids_test\n",
    "input_masks_train, input_masks_valid, input_masks_test = input_masks[idxes[:9000]], input_masks[idxes[9000:10587]], input_masks_test\n",
    "input_types_train, input_types_valid, input_types_test = input_types[idxes[:9000]], input_types[idxes[9000:10587]], input_types_test\n",
    "\n",
    "y_train, y_valid, y_test = labels[idxes[:9000]], labels[idxes[9000:10587]], labels_test\n",
    "\n",
    "print(input_ids_train.shape, y_train.shape, input_ids_valid.shape, y_valid.shape,\n",
    "\n",
    "      input_ids_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rYjRKa-A_ulo"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "  # 如果会出现OOM问题，减小它\n",
    "# 训练集\n",
    "train_data = TensorDataset(torch.LongTensor(input_ids_train),\n",
    "                           torch.LongTensor(input_masks_train),\n",
    "                           torch.LongTensor(input_types_train),\n",
    "                           torch.LongTensor(y_train))\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_loader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "# 验证集\n",
    "valid_data = TensorDataset(torch.LongTensor(input_ids_valid),\n",
    "                          torch.LongTensor(input_masks_valid),\n",
    "                          torch.LongTensor(input_types_valid),\n",
    "                          torch.LongTensor(y_valid))\n",
    "valid_sampler = SequentialSampler(valid_data)\n",
    "valid_loader = DataLoader(valid_data, sampler=valid_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "# 测试集（是没有标签的）\n",
    "test_data = TensorDataset(torch.LongTensor(input_ids_test),\n",
    "                          torch.LongTensor(input_masks_test),\n",
    "                          torch.LongTensor(input_types_test))\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_loader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "wGR6Zw7e_wGU"
   },
   "outputs": [],
   "source": [
    "# 定义model\n",
    "class Bert_Model(nn.Module):\n",
    "    def __init__(self, bert_path, classes=2):\n",
    "        super(Bert_Model, self).__init__()\n",
    "        self.config = BertConfig.from_pretrained(bert_path)  # 导入模型超参数\n",
    "        self.bert = BertModel.from_pretrained(bert_path)     # 加载预训练模型权重\n",
    "        self.fc = nn.Linear(self.config.hidden_size, classes)  # 直接分类\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
    "        outputs = self.bert(input_ids, attention_mask, token_type_ids)\n",
    "        out_pool = outputs[1]   # 池化后的输出 [bs, config.hidden_size]\n",
    "        logit = self.fc(out_pool)   #  [bs, classes]\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eINjetK0_xVi",
    "outputId": "bc346e58-3d2e-46f9-b4bd-d0f4d1220c71"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total parameters: 325524482, Trainable parameters: 325524482\n"
     ]
    }
   ],
   "source": [
    "def get_parameter_number(model):\n",
    "    #  打印模型参数量\n",
    "    total_num = sum(p.numel() for p in model.parameters())\n",
    "    trainable_num = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return 'Total parameters: {}, Trainable parameters: {}'.format(total_num, trainable_num)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "EPOCHS = 5\n",
    "model = Bert_Model(bert_path).to(DEVICE)\n",
    "print(get_parameter_number(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3pEd9jG-_yua"
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=1e-4) #AdamW优化器\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=len(train_loader),\n",
    "                                            num_training_steps=EPOCHS*len(train_loader))\n",
    "# 学习率先线性warmup一个epoch，然后cosine式下降。\n",
    "#加warmup（学习率从0慢慢升上去），如果把warmup去掉，可能收敛不了。\n",
    "\n",
    "# class FocalLoss(nn.Module):\n",
    "#     \"\"\"Multi-class Focal loss implementation\"\"\"\n",
    "#     def __init__(self, gamma=2, weight=None, reduction='mean', ignore_index=-100):\n",
    "#         super(FocalLoss, self).__init__()\n",
    "#         self.gamma = gamma\n",
    "#         self.weight = weight\n",
    "#         self.ignore_index = ignore_index\n",
    "#         self.reduction = reduction\n",
    "\n",
    "    # def forward(self, input, target):\n",
    "    #     \"\"\"\n",
    "    #     input: [N, C]\n",
    "    #     target: [N, ]\n",
    "    #     \"\"\"\n",
    "    #     log_pt = torch.log_softmax(input, dim=1)\n",
    "    #     pt = torch.exp(log_pt)\n",
    "    #     log_pt = (1 - pt) ** self.gamma * log_pt\n",
    "    #     loss = torch.nn.functional.nll_loss(log_pt, target, self.weight, reduction=self.reduction, ignore_index=self.ignore_index)\n",
    "    #     return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "2vAs66vU_0BQ"
   },
   "outputs": [],
   "source": [
    "# 评估模型性能，在验证集上\n",
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    val_true, val_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for idx, (ids, att, tpe, y) in (enumerate(data_loader)):\n",
    "            y_pred = model(ids.to(device), att.to(device), tpe.to(device))\n",
    "            y_pred = torch.argmax(y_pred, dim=1).detach().cpu().numpy().tolist()\n",
    "            val_pred.extend(y_pred)\n",
    "            val_true.extend(y.squeeze().cpu().numpy().tolist())\n",
    "\n",
    "    return accuracy_score(val_true, val_pred)  #返回accuracy\n",
    "\n",
    "# 测试集没有标签，需要预测提交\n",
    "def predict(model, data_loader, device):\n",
    "    model.eval()\n",
    "    val_pred = []\n",
    "    with torch.no_grad():\n",
    "        for idx, (ids, att, tpe) in tqdm(enumerate(data_loader)):\n",
    "            y_pred = model(ids.to(device), att.to(device), tpe.to(device))\n",
    "            y_pred = torch.argmax(y_pred, dim=1).detach().cpu().numpy().tolist()\n",
    "            val_pred.extend(y_pred)\n",
    "    return val_pred\n",
    "\n",
    "def predict(model, data_loader, device):\n",
    "    model.eval()\n",
    "    val_pred = []\n",
    "    with torch.no_grad():\n",
    "        for idx, (ids, att, tpe) in tqdm(enumerate(data_loader)):\n",
    "            y_pred = model(ids.to(device), att.to(device), tpe.to(device))\n",
    "            y_pred = torch.argmax(y_pred, dim=1).detach().cpu().numpy().tolist()\n",
    "            val_pred.extend(y_pred)\n",
    "    return val_pred\n",
    "\n",
    "def train_and_eval(model, train_loader, valid_loader,\n",
    "                   optimizer, scheduler, device, epoch):\n",
    "    best_acc = 0.0\n",
    "    patience = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for i in range(epoch):\n",
    "        \"\"\"训练模型\"\"\"\n",
    "        start = time.time()\n",
    "        model.train()\n",
    "        print(\"***** Running training epoch {} *****\".format(i+1))\n",
    "        train_loss_sum = 0.0\n",
    "        for idx, (ids, att, tpe, y) in enumerate(train_loader):\n",
    "            ids, att, tpe, y = ids.to(device), att.to(device), tpe.to(device), y.to(device)\n",
    "            y_pred = model(ids, att, tpe)\n",
    "            loss = criterion(y_pred, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()   # 学习率变化\n",
    "\n",
    "            train_loss_sum += loss.item()\n",
    "            if (idx + 1) % (len(train_loader)//5) == 0:    # 只打印五次结果\n",
    "                print(\"Epoch {:04d} | Step {:04d}/{:04d} | Loss {:.4f} | Time {:.4f}\".format(\n",
    "                          i+1, idx+1, len(train_loader), train_loss_sum/(idx+1), time.time() - start))\n",
    "                # print(\"Learning rate = {}\".format(optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "\n",
    "        \"\"\"验证模型\"\"\"\n",
    "        model.eval()\n",
    "        acc = evaluate(model, valid_loader, device)  # 验证模型的性能\n",
    "        ## 保存最优模型\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            torch.save(model.state_dict(), \"best_bert_model.pth\")\n",
    "\n",
    "        print(\"current acc is {:.4f}, best acc is {:.4f}\".format(acc, best_acc))\n",
    "        print(\"time costed = {}s \\n\".format(round(time.time() - start, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gmgj8acN_4Tf",
    "outputId": "37086a0c-4511-4be9-9a82-52e21d765be7"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "***** Running training epoch 1 *****\n",
      "Epoch 0001 | Step 0028/0141 | Loss 0.6191 | Time 65.6373\n",
      "Epoch 0001 | Step 0056/0141 | Loss 0.5067 | Time 133.1912\n",
      "Epoch 0001 | Step 0084/0141 | Loss 0.4104 | Time 200.4344\n",
      "Epoch 0001 | Step 0112/0141 | Loss 0.3591 | Time 267.8802\n",
      "Epoch 0001 | Step 0140/0141 | Loss 0.3202 | Time 335.4461\n",
      "current acc is 0.9231, best acc is 0.9231\n",
      "time costed = 385.74772s \n",
      "\n",
      "***** Running training epoch 2 *****\n",
      "Epoch 0002 | Step 0028/0141 | Loss 0.1426 | Time 67.8097\n",
      "Epoch 0002 | Step 0056/0141 | Loss 0.1280 | Time 135.1589\n",
      "Epoch 0002 | Step 0084/0141 | Loss 0.1143 | Time 202.7003\n",
      "Epoch 0002 | Step 0112/0141 | Loss 0.1154 | Time 270.2465\n",
      "Epoch 0002 | Step 0140/0141 | Loss 0.1112 | Time 337.8782\n",
      "current acc is 0.9572, best acc is 0.9572\n",
      "time costed = 365.27472s \n",
      "\n",
      "***** Running training epoch 3 *****\n",
      "Epoch 0003 | Step 0028/0141 | Loss 0.0371 | Time 67.6677\n",
      "Epoch 0003 | Step 0056/0141 | Loss 0.0382 | Time 135.2102\n",
      "Epoch 0003 | Step 0084/0141 | Loss 0.0405 | Time 202.7543\n",
      "Epoch 0003 | Step 0112/0141 | Loss 0.0392 | Time 270.3585\n",
      "Epoch 0003 | Step 0140/0141 | Loss 0.0403 | Time 337.9917\n",
      "current acc is 0.9653, best acc is 0.9653\n",
      "time costed = 365.15185s \n",
      "\n",
      "***** Running training epoch 4 *****\n",
      "Epoch 0004 | Step 0028/0141 | Loss 0.0282 | Time 67.8335\n",
      "Epoch 0004 | Step 0056/0141 | Loss 0.0226 | Time 135.3743\n",
      "Epoch 0004 | Step 0084/0141 | Loss 0.0213 | Time 202.9887\n",
      "Epoch 0004 | Step 0112/0141 | Loss 0.0206 | Time 270.6092\n",
      "Epoch 0004 | Step 0140/0141 | Loss 0.0206 | Time 338.2338\n",
      "current acc is 0.9647, best acc is 0.9653\n",
      "time costed = 360.32257s \n",
      "\n",
      "***** Running training epoch 5 *****\n",
      "Epoch 0005 | Step 0028/0141 | Loss 0.0132 | Time 67.6231\n",
      "Epoch 0005 | Step 0056/0141 | Loss 0.0130 | Time 135.2588\n",
      "Epoch 0005 | Step 0084/0141 | Loss 0.0138 | Time 202.8874\n",
      "Epoch 0005 | Step 0112/0141 | Loss 0.0131 | Time 270.5241\n",
      "Epoch 0005 | Step 0140/0141 | Loss 0.0122 | Time 338.1631\n",
      "current acc is 0.9685, best acc is 0.9685\n",
      "time costed = 365.33785s \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 训练和验证评估\n",
    "train_and_eval(model, train_loader, valid_loader, optimizer, scheduler, DEVICE, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NlvbpXkz_55d",
    "outputId": "2af722a7-dc2b-4aa2-fe97-69b9833c32ce"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "159it [02:11,  1.21it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " Test Accuracy = 0.9245636524997535 \n",
      "\n",
      "\n",
      "  roc_auc_score= 0.8053807798521239 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9400    0.9738    0.9566      8659\n",
      "           1     0.8061    0.6370    0.7116      1482\n",
      "\n",
      "    accuracy                         0.9246     10141\n",
      "   macro avg     0.8731    0.8054    0.8341     10141\n",
      "weighted avg     0.9205    0.9246    0.9208     10141\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best_bert_model.pth\"))\n",
    "pred_test = predict(model, test_loader, DEVICE)\n",
    "print(\"\\n Test Accuracy = {} \\n\".format(accuracy_score(y_test, pred_test)))\n",
    "print(\"\\n  roc_auc_score= {} \\n\".format(roc_auc_score(y_test, pred_test)))\n",
    "print(classification_report(y_test, pred_test, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "NGnF2aizn9yL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
